{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading required modules\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE, CalledProcessError\n",
    "import psycopg2 as db\n",
    "import psycopg2.extras\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import AsIs\n",
    "from encrypt import decryptCredentials,decryptString\n",
    "#from procedures import refreshProcedures\n",
    "import yaml\n",
    "import getpass\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from shapely.wkb import loads\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely.geometry.point import Point\n",
    "from shapely.ops import cascaded_union\n",
    "from geopy.distance import distance\n",
    "\n",
    "import metnoRequests as metno\n",
    "import instantiationBasin as basin\n",
    "\n",
    "import json\n",
    "import gmaps\n",
    "import gmaps.geojson_geometries\n",
    "import geojson\n",
    "\n",
    "#Helper function\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def get_basin_layers(schema,table,column,color='blue',sid=-9999):\n",
    "    conn = db.connect(\"dbname={} user={} host={} password={}\".format(credentials['database'],\n",
    "                                                                       credentials['username'],\n",
    "                                                                        credentials['host'],\n",
    "                                                                        credentials['password']\n",
    "                                                                      )\n",
    "                       )\n",
    "    #And a test query\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(''' SELECT json_build_object(\n",
    "                        'type', 'FeatureCollection',\n",
    "\n",
    "                        'features', json_agg(\n",
    "                            json_build_object(\n",
    "                                'type',       'Feature',\n",
    "                                'label',      station_name,\n",
    "                                'geometry',   ST_AsGeoJSON(ST_ForceRHR(St_Transform(%(column)s,4326)))::json,\n",
    "                                'properties', jsonb_set(row_to_json(%(table)s)::jsonb,'{%(column)s}','0',false)\n",
    "                                )\n",
    "                            )\n",
    "                       )\n",
    "                        FROM %(schema)s.%(table)s;  ''',{\n",
    "                        'schema' : AsIs(schema) ,\n",
    "                        'table'  : AsIs(table),\n",
    "                        'column' : AsIs(column),\n",
    "                         }\n",
    "                  )\n",
    "    layer=cursor.fetchone()[0]\n",
    "    basin_layer = gmaps.geojson_layer(layer,fill_color=color)\n",
    "    #conn.commit()\n",
    "    \n",
    "    cursor.execute('''SELECT a.station_name, st_x(st_transform(a.outlet,4326)),\n",
    "                  st_y(st_transform(a.outlet,4326)), st_area(b.basin)\n",
    "                  FROM %(schema)s.demShp AS a\n",
    "                  INNER JOIN %(schema)s.%(table)s AS b \n",
    "                  ON a.station_id = b.station_id;''',{\n",
    "                    'schema' : AsIs(schema),\n",
    "                    'table' : AsIs(table),\n",
    "                    }\n",
    "                  )  \n",
    "\n",
    "    rows=cursor.fetchall()\n",
    "    #conn.commit()\n",
    "    #conn.close()\n",
    "    outlets = []\n",
    "    for row in rows:\n",
    "        #print(row)\n",
    "        currentDict = {\"name\" : row[0], \"location\": (row[2],row[1]), \"area\": row[3]/1000000}\n",
    "        outlets.append(currentDict)\n",
    "\n",
    "    outlet_locations = [outlet[\"location\"] for outlet in outlets]\n",
    "    outlet_names = [outlet['name'] for outlet in outlets]\n",
    "        \n",
    "    info_box_template = \"\"\"\n",
    "    <dl>\n",
    "    <dt>Name</dt><dd>{name}</dd>\n",
    "    <dt>Area</dt><dd>{area} km<sup>2</sup></dd>\n",
    "    </dl>\n",
    "    \"\"\"                                                \n",
    "    outlet_info = [info_box_template.format(**outlet) for outlet in outlets]                                                 \n",
    "    marker_layer = gmaps.marker_layer(outlet_locations, \n",
    "                                      info_box_content=outlet_info,\n",
    "                                      hover_text=outlet_names)    \n",
    "    \n",
    "    if sid != -9999 :\n",
    "        cursor.execute('''SELECT %(column)s FROM %(schema)s.%(table)s\n",
    "                      WHERE station_id = %(sid)s;'''\n",
    "                      ,{\n",
    "                        'schema' : AsIs(schema),\n",
    "                        'table'  : AsIs(table),\n",
    "                        'column' : AsIs(column),\n",
    "                        'sid'    : AsIs(sid)\n",
    "                          \n",
    "                    }\n",
    "                  )\n",
    "        box = cursor.fetchone()\n",
    "        basin = loads(box[0], hex=True)\n",
    "        basin = cascaded_union(basin)        \n",
    "        return basin_layer,marker_layer,basin\n",
    "            \n",
    "    conn.close()    \n",
    "    return basin_layer,marker_layer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating instance to compute basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance vansjo-basin...\n",
      "NAME          ZONE            MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP    EXTERNAL_IP    STATUS\n",
      "vansjo-basin  europe-west3-a  n1-standard-2               10.156.15.202  35.246.173.27  RUNNING\n",
      "Created [https://www.googleapis.com/compute/beta/projects/nivacatchment/zones/europe-west3-a/instances/vansjo-basin].\n",
      "WARNING: Some requests generated warnings:\n",
      " - Disk size: '50 GB' is larger than image size: '20 GB'. You might need to resize the root repartition manually if the operating system does not support automatic resizing. See https://cloud.google.com/compute/docs/disks/add-persistent-disk#resize_pd for details.\n",
      "\n",
      "(b\"Generating public/private rsa key pair.\\nYour identification has been saved in /home/jose-luis/.ssh/vansjoBasin/jose-luis.\\nYour public key has been saved in /home/jose-luis/.ssh/vansjoBasin/jose-luis.pub.\\nThe key fingerprint is:\\nSHA256:cKup9OW6DJ4tqKmbaFqlRRNZl6Q3avxplZWTLMyPqec jose-luis\\nThe key's randomart image is:\\n+---[RSA 2048]----+\\n|    .o..o.       |\\n|    .. o.o . o   |\\n|    o o + + *    |\\n|   . o = o B .   |\\n|    o + S = .    |\\n|   + . + +       |\\n|  o.o o * .      |\\n|.=.o.B + o       |\\n|%o  +.*o. E      |\\n+----[SHA256]-----+\\n\", b'')\n",
      "Updated [https://www.googleapis.com/compute/v1/projects/nivacatchment/zones/europe-west3-a/instances/vansjo-basin].\n",
      "The ip of the google cloud instance is 35.246.173.27\n",
      "(b'Linux vansjo-basin 4.9.0-6-amd64 #1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07) x86_64\\n\\nThe programs included with the Debian GNU/Linux system are free software;\\nthe exact distribution terms for each program are described in the\\nindividual files in /usr/share/doc/*/copyright.\\n\\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\\npermitted by applicable law.\\n', None)\n"
     ]
    }
   ],
   "source": [
    "instance = 'vansjo-basin'\n",
    "username = 'jose-luis'\n",
    "keyDir = 'vansjoBasin'\n",
    "region = 'europe-west3-a'\n",
    "machineType = 'n1-standard-2'\n",
    "\n",
    "basinGenerator = basin.basin(instance,username,region,keyDir,machineType)\n",
    "basinGenerator.instantiate(fabfile='fabfile_catchment.py')\n",
    "print(\"The ip of the google cloud instance is {}\".format(basinGenerator.ip))\n",
    "\n",
    "#Testing connection to instance\n",
    "time.sleep(2) #Giving time for the editing to work\n",
    "if basinGenerator.instanceExists:\n",
    "    p = Popen(\"ssh -i {0}/{1} {1}@{2} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\".format(\n",
    "            basinGenerator.keyDir,\n",
    "            basinGenerator.username,\n",
    "            basinGenerator.ip\n",
    "            ),\n",
    "            shell=True,stdout=PIPE,stdin=PIPE)\n",
    "    print(p.communicate())\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteo data\n",
    "In this notebook, we'll get the catchment extent for Vansjo and will download meteo data from a nearby wheater station\n",
    "## Setting up credentials and connecting to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Password:  ·······\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to connect\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-91f0c159ce91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to connect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "#Setting up credentials for database access. These should have been previously encrypted\n",
    "token = b'gAAAAABayyyn8ZnEstm8ZQqClUYQ-IqFFuMO4QTbmFJADHWBAcirh52s5stDwSwtVK7qVm5tzdTNFxTQjuRF28b1t2rosFSl_nnTowWrD4itOjkzF7s6Kg_qa1Adqpj59OAfBapgkToUQUHvEFY1Njc4he36AC76gmb8t0CJCq4ze2pDHWIlGdDacZxQ1jq14uLVxrFfCTSxDPX8Mx9W1av723etkOdWvw=='\n",
    "key = getpass.getpass('Password: ')\n",
    "credentials = decryptCredentials(token,key)\n",
    "credentials['host'] = basinGenerator.ip #This is because we don't have a static address for the host. A static address is provided if one uses catchment.niva.no\n",
    "\n",
    "#Setting up credentials for google maps api access\n",
    "apiToken = b'gAAAAABaXyLsGnF3ms4sC3ZhoLCwWAx9q0tydWl8XKEwOy8CO0W6Eqc8J4om8HNDlNR9nExYCmSrelp8W5R-PLtcce1I2UgW3YnlXXqWvrMN-outYwXhZoc59djfF752mzOPqXBHgpNC'\n",
    "apiKey = 'AIzaSyAFYMC28rAKGLZkLb5df_2L6JL_1R93nfY'\n",
    "# apiKey = decryptString(apiToken,key)\n",
    "gmaps.configure(api_key=apiKey)\n",
    "\n",
    "metnoToken = b'gAAAAABaYEqld0O48m09jEyMUBFTdBmZA2BVey2r7FKbo_7zrJPOa1aEGcpW0WmnhGVJHYUPm32f8ttaiboXxAF-Q9hDat3lhsa4ELzrT6J_e402kRDmWi6k0kpldOC2LTBNM9vNLLF4'\n",
    "metnoKey = decryptString(metnoToken, key)\n",
    "metno.init(metnoKey,'https://frost.met.no')\n",
    "\n",
    "# Testing connection to database\n",
    "try : \n",
    "    conn = db.connect(\"dbname={} user={} host={} password={}\".format(credentials['database'],credentials['username'],credentials['host'],credentials['password']))\n",
    "    print('Connection successful!')\n",
    "except :\n",
    "    print(\"Unable to connect\")\n",
    "    \n",
    "conn.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting station outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up outlet\n",
    "station_name = 'Vansjo'\n",
    "longitude = 10.72994\n",
    "latitude = 59.38973\n",
    "epsg = 4326\n",
    "buffer = 55000 \n",
    "station_id = 1\n",
    "\n",
    "stationData = (station_name,\n",
    "               station_id,\n",
    "               longitude,\n",
    "               latitude,\n",
    "               buffer,\n",
    "               str(epsg),\n",
    "               ''\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delineating basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting as user specified in credentials\n",
    "conn = db.connect(\"dbname={} user={} host={} password={}\".format(credentials['database'],\n",
    "                                                                       credentials['username'],\n",
    "                                                                        credentials['host'],\n",
    "                                                                        credentials['password']\n",
    "                                                                      )\n",
    "                       )\n",
    "#And a test query\n",
    "cursor = conn.cursor()\n",
    "\n",
    "db.extras.register_composite('station_info',cursor)\n",
    "\n",
    "#Re-arranging data as a list of tuples and passing it to pg with the help\n",
    "#of pyscopg2 extras\n",
    "allStations = list()\n",
    "allStations.append(stationData)\n",
    "\n",
    "print(allStations)\n",
    "cursor.execute(\"SELECT procedures.initializeStations();\")\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute(\"SELECT procedures.addStations( %s::station_info[] );\",(allStations,))\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "resultsSchema = 'Prognos'\n",
    "\n",
    "\n",
    "cursor.execute(\"SELECT procedures.initializeResultsSchema( %s );\",(resultsSchema,))\n",
    "conn.commit()\n",
    "\n",
    "#Creating table to store base data and results\n",
    "dataTable = 'dem'\n",
    "print('Creating base data...')\n",
    "cursor.execute(\" SELECT procedures.createDataTable(%s,%s);\", (resultsSchema,dataTable))\n",
    "conn.commit()\n",
    "\n",
    "resultsTable = 'results'\n",
    "cursor.execute(\"SELECT procedures.createResultsTable(%s,%s);\",(resultsSchema,resultsTable));\n",
    "conn.commit()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "\n",
    "with Popen(['fab', '-f', basinGenerator.fabfile, 'processSingleBasin:{},{},{},{},{},{},{},{},{}'.format(\n",
    "                                                             credentials['username'],\n",
    "                                                             credentials['password'],\n",
    "                                                             credentials['database'],\n",
    "                                                             resultsSchema,\n",
    "                                                             dataTable,\n",
    "                                                             'flow_dir',\n",
    "                                                             'outlet',\n",
    "                                                             '/home/jose-luis/Trash{}/'.format(station_id),\n",
    "                                                             station_id\n",
    "                                                             )\n",
    "               ], stdout=PIPE, bufsize=1, universal_newlines=True) as p:\n",
    "            #for line in p.stdout:\n",
    "            #    print(line, end='') \n",
    "\n",
    "            if p.returncode != ( 0 or None):\n",
    "                raise subprocess.CalledProcessError(p.returncode, p.args)\n",
    "            print(\"Wa-wa-wee-wa\",p.returncode)\n",
    "            p.wait()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get basin as shape\n",
    "langtjern_layer,marker_layer,basin = get_basin_layers(resultsSchema,resultsTable + 'Shp',\n",
    "                                            'basin',\n",
    "                                            color='green',\n",
    "                                            sid=station_id\n",
    "                                                 )\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(langtjern_layer)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "buffer_layer,marker_layer,buffer = get_basin_layers(resultsSchema,resultsTable + 'Shp',\n",
    "                                            'ST_Transform(ST_SimplifyPreserveTopology(ST_Buffer(basin,10000),3000),4326)',\n",
    "                                           color=(0,100,50,0.2),\n",
    "                                           sid=station_id\n",
    "                                          )\n",
    "fig.add_layer(buffer_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting available data in nearby stations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allStations = metno.getAvailableDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationIds = list(set([i['sourceId'][:-2] for i in allStations['data'] if 'SN' in i['sourceId']]))\n",
    "#The list is too long for a single query, let's split it\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "allCoordinates = []\n",
    "for i in chunks(stationIds,100):\n",
    "    data = metno.getCoordinates(i)\n",
    "    allCoordinates.extend(data['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding nearby stations with meteo variables, given a time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = pd.to_datetime('today').strftime('%Y-%m-%d')\n",
    "datesToGet = '1957-01-01/{}'.format(now) #now\n",
    "start = datesToGet.split('/')\n",
    "finish = pd.datetime.strptime(start[1],'%Y-%m-%d')\n",
    "start = pd.datetime.strptime(start[0],'%Y-%m-%d')\n",
    "\n",
    "def hasInfo(variable,timeResolution='PT1H'):\n",
    "    stationsWithVariable = [i for i in allStations['data'] if variable == i['elementId']\n",
    "                           and 'SN' in i['sourceId']\n",
    "                        #   and start >= pd.datetime.strptime(i['validFrom'],'%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                        #   and (finish <= pd.datetime.strptime(i['validTo'],'%Y-%m-%dT%H:%M:%S.%fZ') if 'validTo' in i else True) \n",
    "                           and i['timeResolution'] == timeResolution\n",
    "                           ]\n",
    "    #Getting rid of repeated stations\n",
    "    stationsWithVariable = {i['sourceId']:i for i in stationsWithVariable}.values()\n",
    "    #Combining with station metada\n",
    "    stationsWithVariable = [  \n",
    "        {\"name\" : b['name'], \n",
    "         \"location\" : b['geometry']['coordinates'][::-1], \n",
    "          \"id\" : a['sourceId'],\n",
    "          \"validFrom\" : a['validFrom'],\n",
    "          #\"validTo\": a,\n",
    "          \"variable\" : a['elementId'],\n",
    "          \"distance\" : \"{:0.2f}\".format(distance([longitude,latitude], b['geometry']['coordinates']).km)\n",
    "        } #dict(a,**b) \n",
    "        for a in stationsWithVariable for b in allCoordinates if a['sourceId'][:-2] == b['id']\n",
    "        and (Point(b['geometry']['coordinates']).within(buffer) if 'geometry' in b else False)\n",
    "    ]\n",
    "    #station = Point(metadata['geometry']['coordinates'])\n",
    "         \n",
    "    return stationsWithVariable\n",
    "\n",
    "\n",
    "# def hasInfo(variable,timeResolution='P1D'):\n",
    "#     stationsWithVariable = [i for i in allStations['data'] if variable == i['elementId']\n",
    "#                            and 'SN' in i['sourceId']\n",
    "#                         #   and start >= pd.datetime.strptime(i['validFrom'],'%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "#                         #   and (finish <= pd.datetime.strptime(i['validTo'],'%Y-%m-%dT%H:%M:%S.%fZ') if 'validTo' in i else True) \n",
    "#                            and i['timeResolution'] == timeResolution\n",
    "#                            ]\n",
    "#     #Getting rid of repeated stations\n",
    "#     stationsWithVariable = {i['sourceId']:i for i in stationsWithVariable}.values()\n",
    "#     #Combining with station metada\n",
    "#     stationsWithVariable = [  \n",
    "#         {\"name\" : b['name'], \n",
    "#          \"location\" : b['geometry']['coordinates'][::-1], \n",
    "#           \"id\" : a['sourceId'],\n",
    "#           \"validFrom\" : a['validFrom'],\n",
    "#           #\"validTo\": a,\n",
    "#           \"variable\" : a['elementId'],\n",
    "#           \"distance\" : \"{:0.2f}\".format(distance([longitude,latitude], b['geometry']['coordinates']).km)\n",
    "#         } #dict(a,**b) \n",
    "#         for a in stationsWithVariable for b in allCoordinates if a['sourceId'][:-2] == b['id']\n",
    "#         and (Point(b['geometry']['coordinates']).within(buffer) if 'geometry' in b else False)\n",
    "#     ]\n",
    "#     #station = Point(metadata['geometry']['coordinates'])\n",
    "#          \n",
    "#     return stationsWithVariable\n",
    "\n",
    "def getMarkerLayer(stations):\n",
    "    info_box_template = \"\"\"\n",
    "    <dl>\n",
    "    <dt>Met station</dt><dd>{name}</dd>\n",
    "    <dt>id</dt><dd>{id}</dd>\n",
    "    <dt>valid from</dt><dd>{validFrom}</dd>\n",
    "    <dt>variable</dt><dd>{variable}</dd>\n",
    "    <dt>distance</dt><dd>{distance} km</dd>\n",
    "    </dl>\n",
    "    \"\"\"    \n",
    "    station_locations = [station[\"location\"] for station in stations]\n",
    "    station_names = [station[\"name\"] for station in stations]\n",
    "    station_info = [info_box_template.format(**station) for station in stations]                                                 \n",
    "    return gmaps.marker_layer(station_locations, info_box_content=station_info,hover_text=station_names)\n",
    "\n",
    "varStations = {}\n",
    "numStations = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='wind_speed'\n",
    "windStations = hasInfo(var)\n",
    "display(windStations)\n",
    "# #Getting data only for the three closest stations\n",
    "varStations['wind_speed'] = sorted(windStations, key=lambda k: float(k['distance']))#[:numStations] \n",
    "\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(getMarkerLayer(windStations))\n",
    "fig.add_layer(buffer_layer)\n",
    "fig.add_layer(langtjern_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windDirStations = hasInfo('wind_from_direction')\n",
    "#varStations['wind_direction'] = sorted(windDirStations, key=lambda k: float(k['distance']))#[:numStations] \n",
    "\n",
    "#fig = gmaps.figure()\n",
    "#fig.add_layer(getMarkerLayer(windDirStations))\n",
    "#fig.add_layer(buffer_layer)\n",
    "#fig.add_layer(langtjern_layer)\n",
    "#fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json\n",
    "import numpy as np\n",
    "queryParameters = {'sources': 'dummy', 'elements': var}\n",
    "metnoUrl = 'https://frost.met.no'\n",
    "#for i in varStations['wind_speed']:\n",
    "queryParameters['sources'] = ','.join([i['id'] for i in varStations['wind_speed']])\n",
    "tsInfo = requests.get(metnoUrl + '/observations/availableTimeSeries/v0.jsonld',\n",
    "                     queryParameters, auth=(metnoKey,'')\n",
    "                     )\n",
    "queryParameters = {'sources' : 'dummy', 'referencetime' : 'dummy', 'elements': var}\n",
    "cnt = 0\n",
    "for i in json.loads(tsInfo.text)['data']:\n",
    "    display('Downloading {}'.format(i['sourceId']))\n",
    "    startDate = i['validFrom']\n",
    "    endDate = i['validTo'] if 'validTo' in i.keys() else '2019-06-01'\n",
    "    queryParameters['referencetime'] = '{}/{}'.format(startDate,endDate)\n",
    "    queryParameters['sources'] = i['sourceId']\n",
    "    response = requests.get(metnoUrl + '/observations/v0.jsonld',\n",
    "                        queryParameters, auth=(metnoKey, '')\n",
    "                        )\n",
    "    data = json.loads(response.text)\n",
    "    values = np.array( [i['observations'][0]['value'] for i in data['data']], dtype='float64')\n",
    "    timestamp = np.array([i['referenceTime'] for i in data['data'] ],dtype='datetime64')\n",
    "    result = pd.DataFrame(data=values,index=timestamp,columns=['{}_{}'.format(var,i['sourceId'])])\n",
    "    if cnt == 0:\n",
    "        allWind = result\n",
    "    else:\n",
    "        allWind = pd.concat([allWind, result], axis=1, sort=False)\n",
    "            \n",
    "   \n",
    "    cnt += 1\n",
    "allWind.plot(subplots=True,figsize=(20,20))\n",
    "allWind.to_csv('windDataHourlyVansjø.txt')\n",
    "#display(allWind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading data from station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(station):\n",
    "    data={}\n",
    "    instantiated=False\n",
    "    data = metno.getTSInfo(station['id'],\n",
    "                           'mean(wind_speed P1D)',\n",
    "                             timeResolution='')\n",
    "    return data\n",
    "\n",
    "allData = {}\n",
    "dataParameters = {}\n",
    "#dataParameters['referencetime'] =  '1980-01-01/1980-06-30'\n",
    "dataParameters['elements'] = 'mean(wind_speed P1D)'\n",
    "dataParameters['sources'] = 'SN17850'\n",
    "\n",
    "# query = requests.get('https://frost.met.no' + '/observations/v0.jsonld',\n",
    "#                          dataParameters,\n",
    "#                          auth=('16474dcc-d1c1-4dca-ab5e-4c04b63cd18d', ''))\n",
    "\n",
    "# display(query)\n",
    "# data = json.loads(query.text)['data']\n",
    "# values = [float(i['observations'][0]['value']) for i in data]\n",
    "# timestamp = np.array([i['referenceTime'] for i in data],dtype='datetime64')\n",
    "# display(timestamp,values)\n",
    "\n",
    "#display(varStations)\n",
    "for key, stations in varStations.items():\n",
    "    display('Downloading {} data'.format(key))\n",
    "    for j in stations:\n",
    "        startDate = j['validFrom']\n",
    "        display(j)\n",
    "        display(getData(j))\n",
    "#     currentStation=getData(stations)\n",
    "#     display('Fuck')\n",
    "#     display(currentStation)\n",
    "    #startDate=currentStation\n",
    "    #display(startDate)\n",
    "    \n",
    "    #allData[key] = getData(stations)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getData(stations):\n",
    "#     data={}\n",
    "#     instantiated=False\n",
    "#     for station in stations:\n",
    "#         df,junk = metno.downloadData(station['id'],\n",
    "#                                       station['variable'],\n",
    "#                                       '2013-06-28/2013-07-31')\n",
    "#         print(df.describe())\n",
    "#         if instantiated is False:\n",
    "#             data=df\n",
    "#             instantiated=True\n",
    "#         else:\n",
    "#             data=pd.merge(data,df,left_index = True, right_index = True, how = 'outer')\n",
    "#     return data\n",
    "\n",
    "\n",
    "# allData = {}\n",
    "# for key, stations in varStations.items():\n",
    "#     display('Downloading {} data'.format(key))\n",
    "#     allData[key] = getData(stations)\n",
    "display(metnoKey)  \n",
    "metno.downloadData('SN17850',\n",
    "                   'wind_speed',\n",
    "                   'latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json\n",
    "import numpy as np\n",
    "\n",
    "dataParameters = {}\n",
    "dataParameters['referencetime'] =  '1980-01-01/1980-06-30'\n",
    "dataParameters['elements'] = 'mean(wind_speed P1D)'\n",
    "dataParameters['sources'] = 'SN17850'\n",
    "\n",
    "query = requests.get('https://frost.met.no' + '/observations/v0.jsonld',\n",
    "                         dataParameters,\n",
    "                         auth=('16474dcc-d1c1-4dca-ab5e-4c04b63cd18d', ''))\n",
    "\n",
    "display(query)\n",
    "data = json.loads(query.text)['data']\n",
    "values = [float(i['observations'][0]['value']) for i in data]\n",
    "timestamp = np.array([i['referenceTime'] for i in data],dtype='datetime64')\n",
    "display(timestamp,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'vansjo.pickle'\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump([varStations,allData], handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotVar(variable):\n",
    "    allData[variable].plot(subplots=True,\n",
    "                           figsize=(20,3*len(allData[variable].columns)),\n",
    "                           marker='.',\n",
    "                           markersize=1,                           \n",
    "                           linestyle='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in allData:\n",
    "    plotVar(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(varStations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
